{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones utiles\n",
    "Drop(): Para eliminar columnas\n",
    "Dropna(axis, condicion): Para eliminar lineas (axis = 0) o columnas (axis = 1). Condicion: 'any' para las lineas que tienen al menos un valor nulo, 'all' para aquellos que tienen todos los valores nulos o subset para elegir una categoria (subset = ['age'] --> borra todos las lineas con valor nulo en edad)\n",
    "\n",
    "Separar los datasets: uno de entrenamiento y uno de testeo.\n",
    "- Métodos para separar:\n",
    "    - Por proporción\n",
    "    - Separación aleatoria\n",
    "    - Separación en capas: el dataset es separado anteriormente según el valor de una variable, después cada una de esas categorías será separada según el indice deseado\n",
    "\n",
    "- Para tratar los datos faltantes, hay varias estrategias:\n",
    "    - Eliminar la columna señalada\n",
    "    - Eliminar las lineas que contienen valores nulos\n",
    "    - Reemplazar los valores faltantes con algún valor decidido anticipadamente\n",
    "\n",
    "- Preparar los atributos numéricos:\n",
    "    - Validacion de datos: semantica y estadisticamente\n",
    "    - Feature engineering: crear nuevos datos a partir de aquellos ya existentes\n",
    "    - Discretizacion: transformar un dato numerico en uno de categoría\n",
    "    - Normalizacion: Volver a traer los datos en intervalos para compararlos mejor. Para algunos algoritmos, la normalizacion es un pre requisito.\n",
    "\n",
    "- Preparar variables categóricas:\n",
    "    - Validacion de datos: semantica y estadisticamente; todas las categorías tienen un significado y la repartición entre las categorías se parece a la realidad\n",
    "    - Modificación de categorías:\n",
    "        - Ordenar o reordenar las categorías\n",
    "        - Modificar la lista de categorías\n",
    "    - Cuantificación: Consiste en transformar una variable categórica en una numérica (los talles S/M/L/XL --> 36/38/40/42)\n",
    "\n",
    "- Revisar los datos particulares como los textos y las fechas\n",
    "\n",
    "- Automatizar la preparación:\n",
    "    - Crear pipelines de tratamiento\n",
    "    - Parámetros de operación y codigo de Pandas\n",
    "\n",
    "\n",
    "Pipelines con Scikit-learn: Sucesión de etapas llamadas TRANSFORMER, encadenadas en el dataset.\n",
    "\n",
    "Creación de un Transformer: Cada transformer posee al menos tres métodos:\n",
    "- Init: Es el constructor del Transformer. Puede contener al menos tres parámetros que serán necesarios luego.\n",
    "- fit: cuando el transformer es llamado sobre los datos de entrenamiento. Puede calcular los parámetros necesarios, almacenados en los atributos\n",
    "- transform: cuando el transformer es llamado sobre los datos de testeo o los datos reales. Va a utilizar los datos calculados anteriormente, con fit, para aplicar las transformaciones correctas sobre los nuevos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class CustomMinMax(BaseEstimator, TransformerMixin):\n",
    "    #Constructor\n",
    "    def __init__(self):\n",
    "        self.min_val = np.NaN\n",
    "        self.max_val = np.NaN\n",
    "    \n",
    "    #Fit method: calculo de min y max    \n",
    "    def fit(self, X, y=None):\n",
    "        self.min_val = X.min()\n",
    "        self.max_val = X.max()\n",
    "        return self\n",
    "    \n",
    "    #Transform method: normalizacion de los datos\n",
    "    def transform(self, X, y=None):\n",
    "        X_scaled = (X - self.min_val) / (self.max_val - self.min_val)\n",
    "        return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar los Transformers directamente implementados en Scikit-learn, se deben seguir tres etapas:\n",
    "- Construir el pipeline indicandole todas las etapas a seguir, en orden, por medio de una tabla de tuplas (nombre, constructor). Se le pueden pasar parametros al constructor\n",
    "- Calcular todas las variables necesarias llamando al metodo fit sobre el pipeline con el dataset de entrenamiento como parametro\n",
    "- Aplicar el pipeline a los datos deseados "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
